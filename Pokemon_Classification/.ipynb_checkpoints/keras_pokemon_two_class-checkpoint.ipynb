{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(10)\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Pokemon.csv')\n",
    "df2 =  df.sort_values(\"Type 1\")\n",
    "df.head(1)\n",
    "number_of_Water = 60\n",
    "number_of_normal = 60\n",
    "\n",
    "total_train = number_of_Water + number_of_normal\n",
    "\n",
    "df2.head()\n",
    "df2 = df[df['Type 1'] =='Water']\n",
    "df_water_train = df2.iloc[0:number_of_Water]\n",
    "df_water_test = df2.iloc[number_of_Water:112]\n",
    "\n",
    "df3 = df[df['Type 1'] =='Normal']\n",
    "df_Normal_train = df3.iloc[0:number_of_normal]\n",
    "df_Normal_test = df3.iloc[number_of_normal:98]\n",
    "\n",
    "train = pd.concat([df_water_train,df_Normal_train],axis=0)\n",
    "test = pd.concat([df_water_test,df_Normal_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Grass', 'Fire', 'Water', 'Bug', 'Normal', 'Poison', 'Electric',\n",
       "       'Ground', 'Fairy', 'Fighting', 'Psychic', 'Rock', 'Ghost', 'Ice',\n",
       "       'Dragon', 'Dark', 'Steel', 'Flying'], dtype=object)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Type 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "      <th>food_map111</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>534</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>CharizardMega Charizard X</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>634</td>\n",
       "      <td>78</td>\n",
       "      <td>130</td>\n",
       "      <td>111</td>\n",
       "      <td>130</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>CharizardMega Charizard Y</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>634</td>\n",
       "      <td>78</td>\n",
       "      <td>104</td>\n",
       "      <td>78</td>\n",
       "      <td>159</td>\n",
       "      <td>115</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>Squirtle</td>\n",
       "      <td>Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>65</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>Wartortle</td>\n",
       "      <td>Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>405</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>Blastoise</td>\n",
       "      <td>Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>530</td>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>85</td>\n",
       "      <td>105</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>BlastoiseMega Blastoise</td>\n",
       "      <td>Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>630</td>\n",
       "      <td>79</td>\n",
       "      <td>103</td>\n",
       "      <td>120</td>\n",
       "      <td>135</td>\n",
       "      <td>115</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>Caterpie</td>\n",
       "      <td>Bug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11</td>\n",
       "      <td>Metapod</td>\n",
       "      <td>Bug</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>Butterfree</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Flying</td>\n",
       "      <td>395</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>Weedle</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Poison</td>\n",
       "      <td>195</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>Kakuna</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Poison</td>\n",
       "      <td>205</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15</td>\n",
       "      <td>Beedrill</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Poison</td>\n",
       "      <td>395</td>\n",
       "      <td>65</td>\n",
       "      <td>90</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15</td>\n",
       "      <td>BeedrillMega Beedrill</td>\n",
       "      <td>Bug</td>\n",
       "      <td>Poison</td>\n",
       "      <td>495</td>\n",
       "      <td>65</td>\n",
       "      <td>150</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16</td>\n",
       "      <td>Pidgey</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Flying</td>\n",
       "      <td>251</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17</td>\n",
       "      <td>Pidgeotto</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Flying</td>\n",
       "      <td>349</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18</td>\n",
       "      <td>Pidgeot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Flying</td>\n",
       "      <td>479</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18</td>\n",
       "      <td>PidgeotMega Pidgeot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Flying</td>\n",
       "      <td>579</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19</td>\n",
       "      <td>Rattata</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>253</td>\n",
       "      <td>30</td>\n",
       "      <td>56</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20</td>\n",
       "      <td>Raticate</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413</td>\n",
       "      <td>55</td>\n",
       "      <td>81</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21</td>\n",
       "      <td>Spearow</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Flying</td>\n",
       "      <td>262</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>22</td>\n",
       "      <td>Fearow</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Flying</td>\n",
       "      <td>442</td>\n",
       "      <td>65</td>\n",
       "      <td>90</td>\n",
       "      <td>65</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23</td>\n",
       "      <td>Ekans</td>\n",
       "      <td>Poison</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>24</td>\n",
       "      <td>Arbok</td>\n",
       "      <td>Poison</td>\n",
       "      <td>NaN</td>\n",
       "      <td>438</td>\n",
       "      <td>60</td>\n",
       "      <td>85</td>\n",
       "      <td>69</td>\n",
       "      <td>65</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>700</td>\n",
       "      <td>Sylveon</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>525</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>701</td>\n",
       "      <td>Hawlucha</td>\n",
       "      <td>Fighting</td>\n",
       "      <td>Flying</td>\n",
       "      <td>500</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "      <td>75</td>\n",
       "      <td>74</td>\n",
       "      <td>63</td>\n",
       "      <td>118</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>702</td>\n",
       "      <td>Dedenne</td>\n",
       "      <td>Electric</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>431</td>\n",
       "      <td>67</td>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>81</td>\n",
       "      <td>67</td>\n",
       "      <td>101</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>703</td>\n",
       "      <td>Carbink</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>704</td>\n",
       "      <td>Goomy</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>35</td>\n",
       "      <td>55</td>\n",
       "      <td>75</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>705</td>\n",
       "      <td>Sliggoo</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>452</td>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "      <td>53</td>\n",
       "      <td>83</td>\n",
       "      <td>113</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>706</td>\n",
       "      <td>Goodra</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>110</td>\n",
       "      <td>150</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>707</td>\n",
       "      <td>Klefki</td>\n",
       "      <td>Steel</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>470</td>\n",
       "      <td>57</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>708</td>\n",
       "      <td>Phantump</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Grass</td>\n",
       "      <td>309</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>709</td>\n",
       "      <td>Trevenant</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Grass</td>\n",
       "      <td>474</td>\n",
       "      <td>85</td>\n",
       "      <td>110</td>\n",
       "      <td>76</td>\n",
       "      <td>65</td>\n",
       "      <td>82</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>710</td>\n",
       "      <td>PumpkabooAverage Size</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Grass</td>\n",
       "      <td>335</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>710</td>\n",
       "      <td>PumpkabooSmall Size</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Grass</td>\n",
       "      <td>335</td>\n",
       "      <td>44</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>710</td>\n",
       "      <td>PumpkabooLarge Size</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Grass</td>\n",
       "      <td>335</td>\n",
       "      <td>54</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>710</td>\n",
       "      <td>PumpkabooSuper Size</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Grass</td>\n",
       "      <td>335</td>\n",
       "      <td>59</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>711</td>\n",
       "      <td>GourgeistAverage Size</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Grass</td>\n",
       "      <td>494</td>\n",
       "      <td>65</td>\n",
       "      <td>90</td>\n",
       "      <td>122</td>\n",
       "      <td>58</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>711</td>\n",
       "      <td>GourgeistSmall Size</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Grass</td>\n",
       "      <td>494</td>\n",
       "      <td>55</td>\n",
       "      <td>85</td>\n",
       "      <td>122</td>\n",
       "      <td>58</td>\n",
       "      <td>75</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>711</td>\n",
       "      <td>GourgeistLarge Size</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Grass</td>\n",
       "      <td>494</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "      <td>122</td>\n",
       "      <td>58</td>\n",
       "      <td>75</td>\n",
       "      <td>69</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>711</td>\n",
       "      <td>GourgeistSuper Size</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>Grass</td>\n",
       "      <td>494</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>122</td>\n",
       "      <td>58</td>\n",
       "      <td>75</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>712</td>\n",
       "      <td>Bergmite</td>\n",
       "      <td>Ice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>304</td>\n",
       "      <td>55</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>713</td>\n",
       "      <td>Avalugg</td>\n",
       "      <td>Ice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>514</td>\n",
       "      <td>95</td>\n",
       "      <td>117</td>\n",
       "      <td>184</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>714</td>\n",
       "      <td>Noibat</td>\n",
       "      <td>Flying</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>245</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>715</td>\n",
       "      <td>Noivern</td>\n",
       "      <td>Flying</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>535</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>97</td>\n",
       "      <td>80</td>\n",
       "      <td>123</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>716</td>\n",
       "      <td>Xerneas</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>680</td>\n",
       "      <td>126</td>\n",
       "      <td>131</td>\n",
       "      <td>95</td>\n",
       "      <td>131</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>717</td>\n",
       "      <td>Yveltal</td>\n",
       "      <td>Dark</td>\n",
       "      <td>Flying</td>\n",
       "      <td>680</td>\n",
       "      <td>126</td>\n",
       "      <td>131</td>\n",
       "      <td>95</td>\n",
       "      <td>131</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>718</td>\n",
       "      <td>Zygarde50% Forme</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Ground</td>\n",
       "      <td>600</td>\n",
       "      <td>108</td>\n",
       "      <td>100</td>\n",
       "      <td>121</td>\n",
       "      <td>81</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>600</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>700</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>600</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>680</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>600</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                       Name    Type 1  Type 2  Total   HP  Attack  \\\n",
       "0      1                  Bulbasaur     Grass  Poison    318   45      49   \n",
       "1      2                    Ivysaur     Grass  Poison    405   60      62   \n",
       "2      3                   Venusaur     Grass  Poison    525   80      82   \n",
       "3      3      VenusaurMega Venusaur     Grass  Poison    625   80     100   \n",
       "4      4                 Charmander      Fire     NaN    309   39      52   \n",
       "5      5                 Charmeleon      Fire     NaN    405   58      64   \n",
       "6      6                  Charizard      Fire  Flying    534   78      84   \n",
       "7      6  CharizardMega Charizard X      Fire  Dragon    634   78     130   \n",
       "8      6  CharizardMega Charizard Y      Fire  Flying    634   78     104   \n",
       "9      7                   Squirtle     Water     NaN    314   44      48   \n",
       "10     8                  Wartortle     Water     NaN    405   59      63   \n",
       "11     9                  Blastoise     Water     NaN    530   79      83   \n",
       "12     9    BlastoiseMega Blastoise     Water     NaN    630   79     103   \n",
       "13    10                   Caterpie       Bug     NaN    195   45      30   \n",
       "14    11                    Metapod       Bug     NaN    205   50      20   \n",
       "15    12                 Butterfree       Bug  Flying    395   60      45   \n",
       "16    13                     Weedle       Bug  Poison    195   40      35   \n",
       "17    14                     Kakuna       Bug  Poison    205   45      25   \n",
       "18    15                   Beedrill       Bug  Poison    395   65      90   \n",
       "19    15      BeedrillMega Beedrill       Bug  Poison    495   65     150   \n",
       "20    16                     Pidgey    Normal  Flying    251   40      45   \n",
       "21    17                  Pidgeotto    Normal  Flying    349   63      60   \n",
       "22    18                    Pidgeot    Normal  Flying    479   83      80   \n",
       "23    18        PidgeotMega Pidgeot    Normal  Flying    579   83      80   \n",
       "24    19                    Rattata    Normal     NaN    253   30      56   \n",
       "25    20                   Raticate    Normal     NaN    413   55      81   \n",
       "26    21                    Spearow    Normal  Flying    262   40      60   \n",
       "27    22                     Fearow    Normal  Flying    442   65      90   \n",
       "28    23                      Ekans    Poison     NaN    288   35      60   \n",
       "29    24                      Arbok    Poison     NaN    438   60      85   \n",
       "..   ...                        ...       ...     ...    ...  ...     ...   \n",
       "770  700                    Sylveon     Fairy     NaN    525   95      65   \n",
       "771  701                   Hawlucha  Fighting  Flying    500   78      92   \n",
       "772  702                    Dedenne  Electric   Fairy    431   67      58   \n",
       "773  703                    Carbink      Rock   Fairy    500   50      50   \n",
       "774  704                      Goomy    Dragon     NaN    300   45      50   \n",
       "775  705                    Sliggoo    Dragon     NaN    452   68      75   \n",
       "776  706                     Goodra    Dragon     NaN    600   90     100   \n",
       "777  707                     Klefki     Steel   Fairy    470   57      80   \n",
       "778  708                   Phantump     Ghost   Grass    309   43      70   \n",
       "779  709                  Trevenant     Ghost   Grass    474   85     110   \n",
       "780  710      PumpkabooAverage Size     Ghost   Grass    335   49      66   \n",
       "781  710        PumpkabooSmall Size     Ghost   Grass    335   44      66   \n",
       "782  710        PumpkabooLarge Size     Ghost   Grass    335   54      66   \n",
       "783  710        PumpkabooSuper Size     Ghost   Grass    335   59      66   \n",
       "784  711      GourgeistAverage Size     Ghost   Grass    494   65      90   \n",
       "785  711        GourgeistSmall Size     Ghost   Grass    494   55      85   \n",
       "786  711        GourgeistLarge Size     Ghost   Grass    494   75      95   \n",
       "787  711        GourgeistSuper Size     Ghost   Grass    494   85     100   \n",
       "788  712                   Bergmite       Ice     NaN    304   55      69   \n",
       "789  713                    Avalugg       Ice     NaN    514   95     117   \n",
       "790  714                     Noibat    Flying  Dragon    245   40      30   \n",
       "791  715                    Noivern    Flying  Dragon    535   85      70   \n",
       "792  716                    Xerneas     Fairy     NaN    680  126     131   \n",
       "793  717                    Yveltal      Dark  Flying    680  126     131   \n",
       "794  718           Zygarde50% Forme    Dragon  Ground    600  108     100   \n",
       "795  719                    Diancie      Rock   Fairy    600   50     100   \n",
       "796  719        DiancieMega Diancie      Rock   Fairy    700   50     160   \n",
       "797  720        HoopaHoopa Confined   Psychic   Ghost    600   80     110   \n",
       "798  720         HoopaHoopa Unbound   Psychic    Dark    680   80     160   \n",
       "799  721                  Volcanion      Fire   Water    600   80     110   \n",
       "\n",
       "     Defense  Sp. Atk  Sp. Def  Speed  Generation  Legendary  food_map111  \\\n",
       "0         49       65       65     45           1      False            0   \n",
       "1         63       80       80     60           1      False            0   \n",
       "2         83      100      100     80           1      False            0   \n",
       "3        123      122      120     80           1      False            0   \n",
       "4         43       60       50     65           1      False            1   \n",
       "5         58       80       65     80           1      False            1   \n",
       "6         78      109       85    100           1      False            1   \n",
       "7        111      130       85    100           1      False            1   \n",
       "8         78      159      115    100           1      False            1   \n",
       "9         65       50       64     43           1      False            2   \n",
       "10        80       65       80     58           1      False            2   \n",
       "11       100       85      105     78           1      False            2   \n",
       "12       120      135      115     78           1      False            2   \n",
       "13        35       20       20     45           1      False            3   \n",
       "14        55       25       25     30           1      False            3   \n",
       "15        50       90       80     70           1      False            3   \n",
       "16        30       20       20     50           1      False            3   \n",
       "17        50       25       25     35           1      False            3   \n",
       "18        40       45       80     75           1      False            3   \n",
       "19        40       15       80    145           1      False            3   \n",
       "20        40       35       35     56           1      False            4   \n",
       "21        55       50       50     71           1      False            4   \n",
       "22        75       70       70    101           1      False            4   \n",
       "23        80      135       80    121           1      False            4   \n",
       "24        35       25       35     72           1      False            4   \n",
       "25        60       50       70     97           1      False            4   \n",
       "26        30       31       31     70           1      False            4   \n",
       "27        65       61       61    100           1      False            4   \n",
       "28        44       40       54     55           1      False            5   \n",
       "29        69       65       79     80           1      False            5   \n",
       "..       ...      ...      ...    ...         ...        ...          ...   \n",
       "770       65      110      130     60           6      False            8   \n",
       "771       75       74       63    118           6      False            9   \n",
       "772       57       81       67    101           6      False            6   \n",
       "773      150       50      150     50           6      False           11   \n",
       "774       35       55       75     40           6      False           14   \n",
       "775       53       83      113     60           6      False           14   \n",
       "776       70      110      150     80           6      False           14   \n",
       "777       91       80       87     75           6      False           16   \n",
       "778       48       50       60     38           6      False           12   \n",
       "779       76       65       82     56           6      False           12   \n",
       "780       70       44       55     51           6      False           12   \n",
       "781       70       44       55     56           6      False           12   \n",
       "782       70       44       55     46           6      False           12   \n",
       "783       70       44       55     41           6      False           12   \n",
       "784      122       58       75     84           6      False           12   \n",
       "785      122       58       75     99           6      False           12   \n",
       "786      122       58       75     69           6      False           12   \n",
       "787      122       58       75     54           6      False           12   \n",
       "788       85       32       35     28           6      False           13   \n",
       "789      184       44       46     28           6      False           13   \n",
       "790       35       45       40     55           6      False           17   \n",
       "791       80       97       80    123           6      False           17   \n",
       "792       95      131       98     99           6       True            8   \n",
       "793       95      131       98     99           6       True           15   \n",
       "794      121       81       95     95           6       True           14   \n",
       "795      150      100      150     50           6       True           11   \n",
       "796      110      160      110    110           6       True           11   \n",
       "797       60      150      130     70           6       True           10   \n",
       "798       60      170      130     80           6       True           10   \n",
       "799      120      130       90     70           6       True            1   \n",
       "\n",
       "     type  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       2  \n",
       "10      2  \n",
       "11      2  \n",
       "12      2  \n",
       "13      3  \n",
       "14      3  \n",
       "15      3  \n",
       "16      3  \n",
       "17      3  \n",
       "18      3  \n",
       "19      3  \n",
       "20      4  \n",
       "21      4  \n",
       "22      4  \n",
       "23      4  \n",
       "24      4  \n",
       "25      4  \n",
       "26      4  \n",
       "27      4  \n",
       "28      5  \n",
       "29      5  \n",
       "..    ...  \n",
       "770     8  \n",
       "771     9  \n",
       "772     6  \n",
       "773    11  \n",
       "774    14  \n",
       "775    14  \n",
       "776    14  \n",
       "777    16  \n",
       "778    12  \n",
       "779    12  \n",
       "780    12  \n",
       "781    12  \n",
       "782    12  \n",
       "783    12  \n",
       "784    12  \n",
       "785    12  \n",
       "786    12  \n",
       "787    12  \n",
       "788    13  \n",
       "789    13  \n",
       "790    17  \n",
       "791    17  \n",
       "792     8  \n",
       "793    15  \n",
       "794    14  \n",
       "795    11  \n",
       "796    11  \n",
       "797    10  \n",
       "798    10  \n",
       "799     1  \n",
       "\n",
       "[800 rows x 15 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def food_map(df):\n",
    "    if df['Type 1'] == 'Grass':\n",
    "        return 0\n",
    "    elif df['Type 1'] == 'Fire':\n",
    "        return 1\n",
    "    elif df['Type 1'] == 'Water':\n",
    "        return 2\n",
    "    elif df['Type 1'] == 'Bug':\n",
    "        return 3\n",
    "    elif df['Type 1'] == 'Normal':\n",
    "        return 4\n",
    "    elif df['Type 1'] == 'Poison':\n",
    "        return 5\n",
    "    elif df['Type 1'] == 'Electric':\n",
    "        return 6\n",
    "    elif df['Type 1'] == 'Ground':\n",
    "        return 7\n",
    "    elif df['Type 1'] == 'Fairy':\n",
    "        return 8\n",
    "    elif df['Type 1'] == 'Fighting':\n",
    "        return 9\n",
    "    elif df['Type 1'] == 'Psychic':\n",
    "        return 10\n",
    "    elif df['Type 1'] == 'Rock':\n",
    "        return 11\n",
    "    elif df['Type 1'] == 'Ghost':\n",
    "        return 12\n",
    "    elif df['Type 1'] == 'Ice':\n",
    "        return 13\n",
    "    elif df['Type 1'] == 'Dragon':\n",
    "        return 14\n",
    "    elif df['Type 1'] == 'Dark':\n",
    "        return 15\n",
    "    elif df['Type 1'] == 'Steel':\n",
    "        return 16\n",
    "    elif df['Type 1'] == 'Flying':\n",
    "        return 17\n",
    "df['type'] = df.apply(food_map,axis = 'columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (train['Type 1']=='Water').values\n",
    "a.shape\n",
    "y_heat=[]\n",
    "for i in range(len(a)):\n",
    "    if a[i]==True :\n",
    "        y_heat.append(1)\n",
    "    else :\n",
    "        y_heat.append(0)\n",
    "        \n",
    "b = (test['Type 1']=='Water').values\n",
    "b.shape\n",
    "y_heat_test=[]\n",
    "for i in range(len(b)):\n",
    "    if b[i]==True :\n",
    "        y_heat_test.append(1)\n",
    "    else :\n",
    "        y_heat_test.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 7)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_matrix_water =   np.array(train['Total'])\n",
    "HP_matrix_water =      np.array(train['HP'])\n",
    "Attack_matrix_water =  np.array(train['Attack'])\n",
    "Defense_matrix_water = np.array(train['Defense'])\n",
    "SpAtk_matrix_water =   np.array(train['Sp. Atk'])\n",
    "SpDef_matrix_water =   np.array(train['Sp. Def'])\n",
    "Speed_matrix_water =   np.array(train['Speed'])\n",
    "\n",
    "train_data = np.vstack((Total_matrix_water,\n",
    "                            HP_matrix_water,\n",
    "                            Attack_matrix_water,\n",
    "                            Defense_matrix_water,\n",
    "                            SpAtk_matrix_water,\n",
    "                            SpDef_matrix_water,\n",
    "                            Speed_matrix_water)).T\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 7)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_matrix_water =   np.array(test['Total'])\n",
    "HP_matrix_water =      np.array(test['HP'])\n",
    "Attack_matrix_water =  np.array(test['Attack'])\n",
    "Defense_matrix_water = np.array(test['Defense'])\n",
    "SpAtk_matrix_water =   np.array(test['Sp. Atk'])\n",
    "SpDef_matrix_water =   np.array(test['Sp. Def'])\n",
    "Speed_matrix_water =   np.array(test['Speed'])\n",
    "\n",
    "test_data = np.vstack((Total_matrix_water,\n",
    "                            HP_matrix_water,\n",
    "                            Attack_matrix_water,\n",
    "                            Defense_matrix_water,\n",
    "                            SpAtk_matrix_water,\n",
    "                            SpDef_matrix_water,\n",
    "                            Speed_matrix_water)).T\n",
    "\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = np.array(y_heat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = np.array(y_heat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n",
    "train_label\n",
    "test_data\n",
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_onehot = np_utils.to_categorical(train_label)\n",
    "test_label_onehot = np_utils.to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10000張影像 每次選100張做一個batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/200\n",
      " - 23s - loss: 0.6826 - acc: 0.5729 - val_loss: 0.8359 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      " - 1s - loss: 0.6676 - acc: 0.6250 - val_loss: 0.9340 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      " - 1s - loss: 0.6633 - acc: 0.6250 - val_loss: 0.9595 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.6629 - acc: 0.6250 - val_loss: 0.9370 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.6616 - acc: 0.6250 - val_loss: 0.9531 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.6608 - acc: 0.6250 - val_loss: 0.9838 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.6651 - acc: 0.6250 - val_loss: 0.9332 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.6605 - acc: 0.6250 - val_loss: 0.9164 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.6602 - acc: 0.6250 - val_loss: 1.0282 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.6590 - acc: 0.6250 - val_loss: 0.9936 - val_acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.6567 - acc: 0.6250 - val_loss: 1.0468 - val_acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.6604 - acc: 0.6250 - val_loss: 1.0394 - val_acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.6580 - acc: 0.6250 - val_loss: 0.9872 - val_acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.6569 - acc: 0.6250 - val_loss: 0.9693 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.6610 - acc: 0.6250 - val_loss: 0.9233 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.6598 - acc: 0.6250 - val_loss: 0.9382 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.6488 - acc: 0.6250 - val_loss: 0.9854 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.6675 - acc: 0.6250 - val_loss: 1.0114 - val_acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.6522 - acc: 0.6250 - val_loss: 0.9933 - val_acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.6456 - acc: 0.6250 - val_loss: 0.9328 - val_acc: 0.0000e+00\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.6513 - acc: 0.6250 - val_loss: 0.9735 - val_acc: 0.0000e+00\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.6548 - acc: 0.6250 - val_loss: 0.8929 - val_acc: 0.0000e+00\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.6473 - acc: 0.6250 - val_loss: 0.9185 - val_acc: 0.0000e+00\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.6465 - acc: 0.6250 - val_loss: 0.9360 - val_acc: 0.0000e+00\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.6348 - acc: 0.6250 - val_loss: 0.9475 - val_acc: 0.0000e+00\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.6339 - acc: 0.6250 - val_loss: 0.9836 - val_acc: 0.0000e+00\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.6269 - acc: 0.6250 - val_loss: 0.9763 - val_acc: 0.0000e+00\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.6218 - acc: 0.6250 - val_loss: 0.9781 - val_acc: 0.0000e+00\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.6281 - acc: 0.6250 - val_loss: 0.9313 - val_acc: 0.0000e+00\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.6167 - acc: 0.6250 - val_loss: 0.9490 - val_acc: 0.0000e+00\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.6142 - acc: 0.6250 - val_loss: 0.9443 - val_acc: 0.0000e+00\n",
      "Epoch 32/200\n",
      " - 2s - loss: 0.6082 - acc: 0.6250 - val_loss: 0.9477 - val_acc: 0.0000e+00\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.6016 - acc: 0.6250 - val_loss: 0.9768 - val_acc: 0.0000e+00\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.6017 - acc: 0.6250 - val_loss: 0.9479 - val_acc: 0.0000e+00\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.5929 - acc: 0.6562 - val_loss: 0.7223 - val_acc: 0.8333\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.5965 - acc: 0.5938 - val_loss: 0.8095 - val_acc: 0.0000e+00\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.5833 - acc: 0.6250 - val_loss: 0.8756 - val_acc: 0.0000e+00\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.5821 - acc: 0.6250 - val_loss: 0.8921 - val_acc: 0.0000e+00\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.5877 - acc: 0.6250 - val_loss: 1.0145 - val_acc: 0.0000e+00\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.5858 - acc: 0.6250 - val_loss: 1.0380 - val_acc: 0.0417\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.5753 - acc: 0.6771 - val_loss: 0.9167 - val_acc: 0.0417\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.5731 - acc: 0.6771 - val_loss: 0.9726 - val_acc: 0.0417\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.5724 - acc: 0.6771 - val_loss: 0.8591 - val_acc: 0.0833\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.5628 - acc: 0.6771 - val_loss: 0.9277 - val_acc: 0.0833\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.5831 - acc: 0.6667 - val_loss: 0.8077 - val_acc: 0.0417\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.6136 - acc: 0.6771 - val_loss: 0.9646 - val_acc: 0.0417\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.5639 - acc: 0.6771 - val_loss: 0.9574 - val_acc: 0.0833\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.5664 - acc: 0.6771 - val_loss: 0.9833 - val_acc: 0.0833\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.5598 - acc: 0.6667 - val_loss: 0.9939 - val_acc: 0.0833\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.5552 - acc: 0.6667 - val_loss: 0.9537 - val_acc: 0.0833\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.5583 - acc: 0.6771 - val_loss: 0.8353 - val_acc: 0.0833\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.5493 - acc: 0.6771 - val_loss: 0.8521 - val_acc: 0.1250\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.5476 - acc: 0.6354 - val_loss: 0.8799 - val_acc: 0.5833\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.5406 - acc: 0.7396 - val_loss: 0.8580 - val_acc: 0.5833\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.5481 - acc: 0.7500 - val_loss: 0.8974 - val_acc: 0.5833\n",
      "Epoch 56/200\n",
      " - 2s - loss: 0.5424 - acc: 0.7500 - val_loss: 0.8072 - val_acc: 0.6667\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.5578 - acc: 0.6979 - val_loss: 0.8576 - val_acc: 0.5833\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.5403 - acc: 0.7396 - val_loss: 0.9121 - val_acc: 0.5833\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.5342 - acc: 0.7708 - val_loss: 0.9566 - val_acc: 0.5417\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.5208 - acc: 0.7500 - val_loss: 0.7648 - val_acc: 0.7500\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.5404 - acc: 0.7500 - val_loss: 0.7589 - val_acc: 0.7500\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.5223 - acc: 0.7812 - val_loss: 0.9268 - val_acc: 0.5833\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.5367 - acc: 0.7188 - val_loss: 0.9953 - val_acc: 0.5000\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.5643 - acc: 0.7083 - val_loss: 1.0220 - val_acc: 0.5000\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.5406 - acc: 0.7812 - val_loss: 0.8815 - val_acc: 0.6250\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.5274 - acc: 0.7604 - val_loss: 0.8672 - val_acc: 0.6250\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.5139 - acc: 0.8021 - val_loss: 0.9851 - val_acc: 0.5417\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.5425 - acc: 0.7708 - val_loss: 0.9123 - val_acc: 0.5833\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.5553 - acc: 0.6354 - val_loss: 1.1545 - val_acc: 0.0000e+00\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.5409 - acc: 0.6667 - val_loss: 0.9859 - val_acc: 0.0833\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.5689 - acc: 0.7083 - val_loss: 0.9510 - val_acc: 0.5833\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.5139 - acc: 0.7917 - val_loss: 0.8431 - val_acc: 0.6667\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.5234 - acc: 0.7500 - val_loss: 0.8651 - val_acc: 0.6667\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.5318 - acc: 0.7500 - val_loss: 0.8899 - val_acc: 0.6250\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.5266 - acc: 0.7812 - val_loss: 0.8217 - val_acc: 0.6667\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.5185 - acc: 0.7604 - val_loss: 0.7707 - val_acc: 0.7500\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.5201 - acc: 0.7812 - val_loss: 0.8168 - val_acc: 0.6667\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.5142 - acc: 0.7917 - val_loss: 0.8863 - val_acc: 0.6250\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.5171 - acc: 0.7604 - val_loss: 0.8454 - val_acc: 0.6667\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.5210 - acc: 0.7500 - val_loss: 0.8741 - val_acc: 0.6667\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.5168 - acc: 0.7604 - val_loss: 0.9827 - val_acc: 0.5417\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.5326 - acc: 0.7396 - val_loss: 0.9139 - val_acc: 0.6250\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.5297 - acc: 0.7396 - val_loss: 0.8734 - val_acc: 0.6667\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.5044 - acc: 0.7708 - val_loss: 0.9101 - val_acc: 0.6250\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.5232 - acc: 0.7708 - val_loss: 0.7378 - val_acc: 0.7500\n",
      "Epoch 86/200\n",
      " - 1s - loss: 0.5263 - acc: 0.7604 - val_loss: 0.8406 - val_acc: 0.6667\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.5041 - acc: 0.7812 - val_loss: 0.8790 - val_acc: 0.6667\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.5081 - acc: 0.7812 - val_loss: 0.9275 - val_acc: 0.6250\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.5278 - acc: 0.7604 - val_loss: 0.6190 - val_acc: 0.8750\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.5251 - acc: 0.7500 - val_loss: 0.9564 - val_acc: 0.5833\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.5354 - acc: 0.7500 - val_loss: 0.8357 - val_acc: 0.6667\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.5108 - acc: 0.7812 - val_loss: 0.9273 - val_acc: 0.5833\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.5124 - acc: 0.7812 - val_loss: 0.7583 - val_acc: 0.7083\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.5223 - acc: 0.7500 - val_loss: 0.6749 - val_acc: 0.8333\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.5206 - acc: 0.7708 - val_loss: 0.9094 - val_acc: 0.6250\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.5120 - acc: 0.7708 - val_loss: 0.8286 - val_acc: 0.6667\n",
      "Epoch 97/200\n",
      " - 1s - loss: 0.5207 - acc: 0.7604 - val_loss: 0.8535 - val_acc: 0.6667\n",
      "Epoch 98/200\n",
      " - 1s - loss: 0.5066 - acc: 0.7708 - val_loss: 0.8150 - val_acc: 0.7083\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.5228 - acc: 0.7917 - val_loss: 1.0033 - val_acc: 0.5417\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.5172 - acc: 0.7604 - val_loss: 0.7662 - val_acc: 0.7083\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.5255 - acc: 0.7188 - val_loss: 0.7928 - val_acc: 0.7083\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.5042 - acc: 0.7708 - val_loss: 0.8519 - val_acc: 0.6667\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.5028 - acc: 0.7812 - val_loss: 1.0072 - val_acc: 0.5417\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.4912 - acc: 0.7604 - val_loss: 0.6762 - val_acc: 0.8333\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.5212 - acc: 0.7604 - val_loss: 0.7910 - val_acc: 0.7083\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.4864 - acc: 0.7812 - val_loss: 0.7132 - val_acc: 0.7500\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.5101 - acc: 0.7708 - val_loss: 0.7215 - val_acc: 0.7500\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.4969 - acc: 0.7812 - val_loss: 0.7037 - val_acc: 0.7500\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.5147 - acc: 0.7812 - val_loss: 0.9294 - val_acc: 0.6250\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.5149 - acc: 0.7500 - val_loss: 0.8447 - val_acc: 0.6667\n",
      "Epoch 111/200\n",
      " - 2s - loss: 0.5385 - acc: 0.7604 - val_loss: 0.7433 - val_acc: 0.7083\n",
      "Epoch 112/200\n",
      " - 2s - loss: 0.5023 - acc: 0.7708 - val_loss: 0.9266 - val_acc: 0.5833\n",
      "Epoch 113/200\n",
      " - 2s - loss: 0.5762 - acc: 0.7396 - val_loss: 0.8579 - val_acc: 0.6250\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.5098 - acc: 0.7500 - val_loss: 0.7230 - val_acc: 0.7083\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.4936 - acc: 0.7917 - val_loss: 0.9261 - val_acc: 0.5833\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.5110 - acc: 0.7604 - val_loss: 0.8027 - val_acc: 0.7083\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.5014 - acc: 0.7812 - val_loss: 0.8956 - val_acc: 0.6250\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.5086 - acc: 0.7812 - val_loss: 0.8771 - val_acc: 0.6667\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.5292 - acc: 0.7604 - val_loss: 0.7946 - val_acc: 0.7083\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.4979 - acc: 0.7604 - val_loss: 0.6966 - val_acc: 0.7500\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.4999 - acc: 0.7812 - val_loss: 0.9732 - val_acc: 0.5833\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.5124 - acc: 0.7500 - val_loss: 0.6731 - val_acc: 0.7500\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.4903 - acc: 0.7812 - val_loss: 0.9201 - val_acc: 0.6250\n",
      "Epoch 124/200\n",
      " - 1s - loss: 0.4997 - acc: 0.7812 - val_loss: 0.9618 - val_acc: 0.6250\n",
      "Epoch 125/200\n",
      " - 1s - loss: 0.5004 - acc: 0.7708 - val_loss: 0.8593 - val_acc: 0.6667\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.4997 - acc: 0.7708 - val_loss: 0.8105 - val_acc: 0.6667\n",
      "Epoch 127/200\n",
      " - 1s - loss: 0.4945 - acc: 0.7812 - val_loss: 0.8807 - val_acc: 0.6667\n",
      "Epoch 128/200\n",
      " - 2s - loss: 0.5079 - acc: 0.7396 - val_loss: 0.8235 - val_acc: 0.6667\n",
      "Epoch 129/200\n",
      " - 2s - loss: 0.5295 - acc: 0.7604 - val_loss: 0.8280 - val_acc: 0.6667\n",
      "Epoch 130/200\n",
      " - 2s - loss: 0.5143 - acc: 0.7500 - val_loss: 0.7178 - val_acc: 0.7500\n",
      "Epoch 131/200\n",
      " - 2s - loss: 0.5194 - acc: 0.7604 - val_loss: 0.9851 - val_acc: 0.5833\n",
      "Epoch 132/200\n",
      " - 2s - loss: 0.5340 - acc: 0.7500 - val_loss: 0.7818 - val_acc: 0.6667\n",
      "Epoch 133/200\n",
      " - 2s - loss: 0.4871 - acc: 0.7812 - val_loss: 1.0355 - val_acc: 0.5417\n",
      "Epoch 134/200\n",
      " - 1s - loss: 0.5321 - acc: 0.7604 - val_loss: 0.8208 - val_acc: 0.6667\n",
      "Epoch 135/200\n",
      " - 1s - loss: 0.4827 - acc: 0.7917 - val_loss: 1.0185 - val_acc: 0.5833\n",
      "Epoch 136/200\n",
      " - 1s - loss: 0.5122 - acc: 0.7708 - val_loss: 0.9036 - val_acc: 0.6250\n",
      "Epoch 137/200\n",
      " - 1s - loss: 0.4976 - acc: 0.7708 - val_loss: 1.0116 - val_acc: 0.5833\n",
      "Epoch 138/200\n",
      " - 1s - loss: 0.4997 - acc: 0.7812 - val_loss: 0.8931 - val_acc: 0.6250\n",
      "Epoch 139/200\n",
      " - 1s - loss: 0.5009 - acc: 0.7708 - val_loss: 0.8227 - val_acc: 0.6667\n",
      "Epoch 140/200\n",
      " - 1s - loss: 0.4953 - acc: 0.7812 - val_loss: 0.8530 - val_acc: 0.6667\n",
      "Epoch 141/200\n",
      " - 1s - loss: 0.4941 - acc: 0.7917 - val_loss: 0.7172 - val_acc: 0.7500\n",
      "Epoch 142/200\n",
      " - 1s - loss: 0.4913 - acc: 0.7812 - val_loss: 0.9383 - val_acc: 0.6250\n",
      "Epoch 143/200\n",
      " - 1s - loss: 0.5060 - acc: 0.7500 - val_loss: 0.8744 - val_acc: 0.6667\n",
      "Epoch 144/200\n",
      " - 1s - loss: 0.4949 - acc: 0.7917 - val_loss: 1.0254 - val_acc: 0.5833\n",
      "Epoch 145/200\n",
      " - 1s - loss: 0.4970 - acc: 0.7812 - val_loss: 0.9501 - val_acc: 0.6250\n",
      "Epoch 146/200\n",
      " - 1s - loss: 0.5051 - acc: 0.7708 - val_loss: 1.0464 - val_acc: 0.5417\n",
      "Epoch 147/200\n",
      " - 1s - loss: 0.5052 - acc: 0.7500 - val_loss: 0.8037 - val_acc: 0.6667\n",
      "Epoch 148/200\n",
      " - 1s - loss: 0.5019 - acc: 0.7708 - val_loss: 0.7167 - val_acc: 0.7500\n",
      "Epoch 149/200\n",
      " - 1s - loss: 0.4883 - acc: 0.7604 - val_loss: 0.9252 - val_acc: 0.6250\n",
      "Epoch 150/200\n",
      " - 1s - loss: 0.4952 - acc: 0.7604 - val_loss: 0.9364 - val_acc: 0.6250\n",
      "Epoch 151/200\n",
      " - 1s - loss: 0.4898 - acc: 0.7708 - val_loss: 0.9520 - val_acc: 0.6250\n",
      "Epoch 152/200\n",
      " - 1s - loss: 0.4946 - acc: 0.7812 - val_loss: 0.9114 - val_acc: 0.6250\n",
      "Epoch 153/200\n",
      " - 1s - loss: 0.5055 - acc: 0.7708 - val_loss: 0.9515 - val_acc: 0.6250\n",
      "Epoch 154/200\n",
      " - 1s - loss: 0.4950 - acc: 0.7604 - val_loss: 0.8040 - val_acc: 0.6667\n",
      "Epoch 155/200\n",
      " - 1s - loss: 0.4901 - acc: 0.7708 - val_loss: 0.7109 - val_acc: 0.7500\n",
      "Epoch 156/200\n",
      " - 1s - loss: 0.4837 - acc: 0.7708 - val_loss: 0.6429 - val_acc: 0.8333\n",
      "Epoch 157/200\n",
      " - 1s - loss: 0.4997 - acc: 0.7812 - val_loss: 0.8221 - val_acc: 0.6667\n",
      "Epoch 158/200\n",
      " - 1s - loss: 0.4879 - acc: 0.7917 - val_loss: 0.7097 - val_acc: 0.7917\n",
      "Epoch 159/200\n",
      " - 1s - loss: 0.5385 - acc: 0.6979 - val_loss: 0.8225 - val_acc: 0.7917\n",
      "Epoch 160/200\n",
      " - 1s - loss: 0.5054 - acc: 0.7812 - val_loss: 0.9898 - val_acc: 0.6667\n",
      "Epoch 161/200\n",
      " - 1s - loss: 0.4932 - acc: 0.7812 - val_loss: 0.9988 - val_acc: 0.6250\n",
      "Epoch 162/200\n",
      " - 1s - loss: 0.4935 - acc: 0.7917 - val_loss: 0.8681 - val_acc: 0.7083\n",
      "Epoch 163/200\n",
      " - 1s - loss: 0.4993 - acc: 0.7708 - val_loss: 0.7946 - val_acc: 0.7083\n",
      "Epoch 164/200\n",
      " - 1s - loss: 0.5077 - acc: 0.7500 - val_loss: 0.8695 - val_acc: 0.6667\n",
      "Epoch 165/200\n",
      " - 1s - loss: 0.4830 - acc: 0.7708 - val_loss: 0.9790 - val_acc: 0.6250\n",
      "Epoch 166/200\n",
      " - 1s - loss: 0.5061 - acc: 0.7708 - val_loss: 0.9258 - val_acc: 0.6667\n",
      "Epoch 167/200\n",
      " - 1s - loss: 0.4896 - acc: 0.7812 - val_loss: 0.9762 - val_acc: 0.6250\n",
      "Epoch 168/200\n",
      " - 1s - loss: 0.4990 - acc: 0.7396 - val_loss: 0.7677 - val_acc: 0.7500\n",
      "Epoch 169/200\n",
      " - 1s - loss: 0.4929 - acc: 0.7708 - val_loss: 0.9103 - val_acc: 0.6667\n",
      "Epoch 170/200\n",
      " - 1s - loss: 0.5172 - acc: 0.7396 - val_loss: 0.8939 - val_acc: 0.6667\n",
      "Epoch 171/200\n",
      " - 1s - loss: 0.5056 - acc: 0.7500 - val_loss: 0.8341 - val_acc: 0.7083\n",
      "Epoch 172/200\n",
      " - 1s - loss: 0.4857 - acc: 0.7812 - val_loss: 0.9503 - val_acc: 0.6250\n",
      "Epoch 173/200\n",
      " - 1s - loss: 0.4932 - acc: 0.7708 - val_loss: 0.7020 - val_acc: 0.7500\n",
      "Epoch 174/200\n",
      " - 1s - loss: 0.4815 - acc: 0.7708 - val_loss: 0.6841 - val_acc: 0.7917\n",
      "Epoch 175/200\n",
      " - 1s - loss: 0.4990 - acc: 0.7708 - val_loss: 0.7746 - val_acc: 0.7500\n",
      "Epoch 176/200\n",
      " - 1s - loss: 0.4818 - acc: 0.7500 - val_loss: 0.9790 - val_acc: 0.6250\n",
      "Epoch 177/200\n",
      " - 1s - loss: 0.5075 - acc: 0.7292 - val_loss: 0.7495 - val_acc: 0.7500\n",
      "Epoch 178/200\n",
      " - 1s - loss: 0.5172 - acc: 0.7604 - val_loss: 0.6897 - val_acc: 0.7500\n",
      "Epoch 179/200\n",
      " - 1s - loss: 0.5131 - acc: 0.7396 - val_loss: 0.7189 - val_acc: 0.7500\n",
      "Epoch 180/200\n",
      " - 1s - loss: 0.5143 - acc: 0.7708 - val_loss: 0.9875 - val_acc: 0.6250\n",
      "Epoch 181/200\n",
      " - 1s - loss: 0.5068 - acc: 0.7500 - val_loss: 0.8273 - val_acc: 0.7083\n",
      "Epoch 182/200\n",
      " - 1s - loss: 0.5023 - acc: 0.7604 - val_loss: 0.6964 - val_acc: 0.8333\n",
      "Epoch 183/200\n",
      " - 1s - loss: 0.4908 - acc: 0.7708 - val_loss: 0.9336 - val_acc: 0.6667\n",
      "Epoch 184/200\n",
      " - 1s - loss: 0.5019 - acc: 0.7500 - val_loss: 0.8552 - val_acc: 0.7083\n",
      "Epoch 185/200\n",
      " - 1s - loss: 0.4958 - acc: 0.7812 - val_loss: 0.8286 - val_acc: 0.7083\n",
      "Epoch 186/200\n",
      " - 1s - loss: 0.5047 - acc: 0.7604 - val_loss: 0.8906 - val_acc: 0.6667\n",
      "Epoch 187/200\n",
      " - 1s - loss: 0.4980 - acc: 0.7604 - val_loss: 0.7757 - val_acc: 0.7500\n",
      "Epoch 188/200\n",
      " - 1s - loss: 0.5088 - acc: 0.7708 - val_loss: 0.8516 - val_acc: 0.7083\n",
      "Epoch 189/200\n",
      " - 1s - loss: 0.5286 - acc: 0.7604 - val_loss: 1.0906 - val_acc: 0.5417\n",
      "Epoch 190/200\n",
      " - 1s - loss: 0.5335 - acc: 0.7500 - val_loss: 0.8051 - val_acc: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/200\n",
      " - 1s - loss: 0.4941 - acc: 0.7604 - val_loss: 0.9493 - val_acc: 0.6250\n",
      "Epoch 192/200\n",
      " - 1s - loss: 0.4911 - acc: 0.7812 - val_loss: 0.7504 - val_acc: 0.7083\n",
      "Epoch 193/200\n",
      " - 1s - loss: 0.4754 - acc: 0.7812 - val_loss: 0.6447 - val_acc: 0.8333\n",
      "Epoch 194/200\n",
      " - 1s - loss: 0.5029 - acc: 0.7708 - val_loss: 0.8850 - val_acc: 0.6667\n",
      "Epoch 195/200\n",
      " - 1s - loss: 0.4895 - acc: 0.7604 - val_loss: 0.9363 - val_acc: 0.6250\n",
      "Epoch 196/200\n",
      " - 1s - loss: 0.4904 - acc: 0.7604 - val_loss: 0.7647 - val_acc: 0.7083\n",
      "Epoch 197/200\n",
      " - 1s - loss: 0.5059 - acc: 0.7812 - val_loss: 0.7796 - val_acc: 0.7083\n",
      "Epoch 198/200\n",
      " - 1s - loss: 0.4932 - acc: 0.7812 - val_loss: 0.8662 - val_acc: 0.6667\n",
      "Epoch 199/200\n",
      " - 1s - loss: 0.5212 - acc: 0.7292 - val_loss: 0.7744 - val_acc: 0.7083\n",
      "Epoch 200/200\n",
      " - 1s - loss: 0.4961 - acc: 0.7500 - val_loss: 0.8207 - val_acc: 0.7083\n",
      "90/90 [==============================] - 0s 300us/step\n",
      "\n",
      "準確率= 0.6333333293596903\n",
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/200\n",
      " - 25s - loss: 0.6685 - acc: 0.6250 - val_loss: 0.8958 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      " - 1s - loss: 0.6585 - acc: 0.6250 - val_loss: 0.9776 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      " - 1s - loss: 0.6564 - acc: 0.6250 - val_loss: 0.9454 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      " - 1s - loss: 0.6573 - acc: 0.6250 - val_loss: 0.9223 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      " - 1s - loss: 0.6543 - acc: 0.6250 - val_loss: 0.9326 - val_acc: 0.0417\n",
      "Epoch 6/200\n",
      " - 1s - loss: 0.6462 - acc: 0.6250 - val_loss: 0.9443 - val_acc: 0.0417\n",
      "Epoch 7/200\n",
      " - 1s - loss: 0.6421 - acc: 0.6250 - val_loss: 0.8396 - val_acc: 0.0417\n",
      "Epoch 8/200\n",
      " - 1s - loss: 0.6350 - acc: 0.6667 - val_loss: 0.8089 - val_acc: 0.0417\n",
      "Epoch 9/200\n",
      " - 1s - loss: 0.6365 - acc: 0.6458 - val_loss: 0.8268 - val_acc: 0.0417\n",
      "Epoch 10/200\n",
      " - 1s - loss: 0.6349 - acc: 0.6458 - val_loss: 0.8636 - val_acc: 0.0417\n",
      "Epoch 11/200\n",
      " - 1s - loss: 0.6307 - acc: 0.6354 - val_loss: 0.9452 - val_acc: 0.0417\n",
      "Epoch 12/200\n",
      " - 1s - loss: 0.6372 - acc: 0.6458 - val_loss: 1.0181 - val_acc: 0.0417\n",
      "Epoch 13/200\n",
      " - 1s - loss: 0.6204 - acc: 0.6250 - val_loss: 0.6940 - val_acc: 0.7083\n",
      "Epoch 14/200\n",
      " - 1s - loss: 0.6181 - acc: 0.6562 - val_loss: 1.0256 - val_acc: 0.0417\n",
      "Epoch 15/200\n",
      " - 1s - loss: 0.6150 - acc: 0.6562 - val_loss: 0.8639 - val_acc: 0.0833\n",
      "Epoch 16/200\n",
      " - 1s - loss: 0.6014 - acc: 0.6875 - val_loss: 0.8107 - val_acc: 0.4167\n",
      "Epoch 17/200\n",
      " - 1s - loss: 0.6068 - acc: 0.6667 - val_loss: 0.8704 - val_acc: 0.2083\n",
      "Epoch 18/200\n",
      " - 1s - loss: 0.5913 - acc: 0.6458 - val_loss: 1.1674 - val_acc: 0.0417\n",
      "Epoch 19/200\n",
      " - 1s - loss: 0.6045 - acc: 0.6354 - val_loss: 0.8607 - val_acc: 0.0833\n",
      "Epoch 20/200\n",
      " - 1s - loss: 0.5828 - acc: 0.6875 - val_loss: 0.9552 - val_acc: 0.1250\n",
      "Epoch 21/200\n",
      " - 1s - loss: 0.5820 - acc: 0.6562 - val_loss: 0.7610 - val_acc: 0.5833\n",
      "Epoch 22/200\n",
      " - 1s - loss: 0.5791 - acc: 0.6875 - val_loss: 0.9529 - val_acc: 0.3333\n",
      "Epoch 23/200\n",
      " - 1s - loss: 0.5750 - acc: 0.7188 - val_loss: 0.7662 - val_acc: 0.5417\n",
      "Epoch 24/200\n",
      " - 1s - loss: 0.5651 - acc: 0.7083 - val_loss: 0.7407 - val_acc: 0.6667\n",
      "Epoch 25/200\n",
      " - 1s - loss: 0.5568 - acc: 0.7708 - val_loss: 0.9888 - val_acc: 0.2083\n",
      "Epoch 26/200\n",
      " - 1s - loss: 0.5823 - acc: 0.6771 - val_loss: 0.7765 - val_acc: 0.5833\n",
      "Epoch 27/200\n",
      " - 1s - loss: 0.5640 - acc: 0.6979 - val_loss: 0.7603 - val_acc: 0.7083\n",
      "Epoch 28/200\n",
      " - 1s - loss: 0.5488 - acc: 0.7604 - val_loss: 0.5754 - val_acc: 0.8333\n",
      "Epoch 29/200\n",
      " - 1s - loss: 0.5617 - acc: 0.7396 - val_loss: 0.9684 - val_acc: 0.2917\n",
      "Epoch 30/200\n",
      " - 1s - loss: 0.5613 - acc: 0.7396 - val_loss: 0.7619 - val_acc: 0.6250\n",
      "Epoch 31/200\n",
      " - 1s - loss: 0.5616 - acc: 0.7604 - val_loss: 0.7456 - val_acc: 0.6250\n",
      "Epoch 32/200\n",
      " - 1s - loss: 0.5317 - acc: 0.8021 - val_loss: 1.0570 - val_acc: 0.2083\n",
      "Epoch 33/200\n",
      " - 1s - loss: 0.5679 - acc: 0.6771 - val_loss: 0.6544 - val_acc: 0.6667\n",
      "Epoch 34/200\n",
      " - 1s - loss: 0.5930 - acc: 0.7500 - val_loss: 0.9150 - val_acc: 0.1250\n",
      "Epoch 35/200\n",
      " - 1s - loss: 0.5865 - acc: 0.6458 - val_loss: 0.9703 - val_acc: 0.1667\n",
      "Epoch 36/200\n",
      " - 1s - loss: 0.5813 - acc: 0.6667 - val_loss: 0.7902 - val_acc: 0.3750\n",
      "Epoch 37/200\n",
      " - 1s - loss: 0.5603 - acc: 0.7188 - val_loss: 0.6326 - val_acc: 0.7083\n",
      "Epoch 38/200\n",
      " - 1s - loss: 0.5675 - acc: 0.7396 - val_loss: 0.7624 - val_acc: 0.5417\n",
      "Epoch 39/200\n",
      " - 1s - loss: 0.5216 - acc: 0.7500 - val_loss: 0.7660 - val_acc: 0.6250\n",
      "Epoch 40/200\n",
      " - 1s - loss: 0.6013 - acc: 0.6562 - val_loss: 0.7430 - val_acc: 0.6250\n",
      "Epoch 41/200\n",
      " - 1s - loss: 0.5471 - acc: 0.7292 - val_loss: 0.7420 - val_acc: 0.7083\n",
      "Epoch 42/200\n",
      " - 1s - loss: 0.5239 - acc: 0.7396 - val_loss: 0.8886 - val_acc: 0.5833\n",
      "Epoch 43/200\n",
      " - 1s - loss: 0.5398 - acc: 0.7500 - val_loss: 0.8367 - val_acc: 0.5833\n",
      "Epoch 44/200\n",
      " - 1s - loss: 0.5306 - acc: 0.7604 - val_loss: 1.0739 - val_acc: 0.4583\n",
      "Epoch 45/200\n",
      " - 1s - loss: 0.5223 - acc: 0.7708 - val_loss: 0.6999 - val_acc: 0.7083\n",
      "Epoch 46/200\n",
      " - 1s - loss: 0.5291 - acc: 0.7708 - val_loss: 0.8877 - val_acc: 0.5000\n",
      "Epoch 47/200\n",
      " - 1s - loss: 0.5436 - acc: 0.7292 - val_loss: 0.7534 - val_acc: 0.7500\n",
      "Epoch 48/200\n",
      " - 1s - loss: 0.5151 - acc: 0.7604 - val_loss: 0.7948 - val_acc: 0.6250\n",
      "Epoch 49/200\n",
      " - 1s - loss: 0.5106 - acc: 0.7708 - val_loss: 0.9804 - val_acc: 0.5000\n",
      "Epoch 50/200\n",
      " - 1s - loss: 0.5464 - acc: 0.7292 - val_loss: 0.8194 - val_acc: 0.5000\n",
      "Epoch 51/200\n",
      " - 1s - loss: 0.5061 - acc: 0.8021 - val_loss: 1.0632 - val_acc: 0.4583\n",
      "Epoch 52/200\n",
      " - 1s - loss: 0.5171 - acc: 0.7708 - val_loss: 0.7874 - val_acc: 0.5417\n",
      "Epoch 53/200\n",
      " - 1s - loss: 0.5015 - acc: 0.7604 - val_loss: 0.7178 - val_acc: 0.7083\n",
      "Epoch 54/200\n",
      " - 1s - loss: 0.5178 - acc: 0.7604 - val_loss: 0.9561 - val_acc: 0.5417\n",
      "Epoch 55/200\n",
      " - 1s - loss: 0.5140 - acc: 0.7396 - val_loss: 0.6858 - val_acc: 0.7500\n",
      "Epoch 56/200\n",
      " - 1s - loss: 0.5167 - acc: 0.7604 - val_loss: 1.0449 - val_acc: 0.5000\n",
      "Epoch 57/200\n",
      " - 1s - loss: 0.5375 - acc: 0.7500 - val_loss: 0.7824 - val_acc: 0.7083\n",
      "Epoch 58/200\n",
      " - 1s - loss: 0.5138 - acc: 0.7500 - val_loss: 0.6992 - val_acc: 0.6250\n",
      "Epoch 59/200\n",
      " - 1s - loss: 0.5122 - acc: 0.7292 - val_loss: 0.6665 - val_acc: 0.7500\n",
      "Epoch 60/200\n",
      " - 1s - loss: 0.5202 - acc: 0.7396 - val_loss: 0.8299 - val_acc: 0.6667\n",
      "Epoch 61/200\n",
      " - 1s - loss: 0.5266 - acc: 0.7292 - val_loss: 0.9605 - val_acc: 0.5417\n",
      "Epoch 62/200\n",
      " - 1s - loss: 0.5128 - acc: 0.7500 - val_loss: 1.0460 - val_acc: 0.4583\n",
      "Epoch 63/200\n",
      " - 1s - loss: 0.5212 - acc: 0.7500 - val_loss: 0.7016 - val_acc: 0.7083\n",
      "Epoch 64/200\n",
      " - 1s - loss: 0.5101 - acc: 0.7292 - val_loss: 0.7425 - val_acc: 0.5417\n",
      "Epoch 65/200\n",
      " - 1s - loss: 0.5051 - acc: 0.7500 - val_loss: 0.6962 - val_acc: 0.7083\n",
      "Epoch 66/200\n",
      " - 1s - loss: 0.4954 - acc: 0.7604 - val_loss: 0.8162 - val_acc: 0.6667\n",
      "Epoch 67/200\n",
      " - 1s - loss: 0.5244 - acc: 0.7083 - val_loss: 0.7445 - val_acc: 0.5417\n",
      "Epoch 68/200\n",
      " - 1s - loss: 0.5589 - acc: 0.6979 - val_loss: 0.8379 - val_acc: 0.5417\n",
      "Epoch 69/200\n",
      " - 1s - loss: 0.5407 - acc: 0.7500 - val_loss: 0.7775 - val_acc: 0.5000\n",
      "Epoch 70/200\n",
      " - 1s - loss: 0.5409 - acc: 0.7083 - val_loss: 0.7665 - val_acc: 0.6667\n",
      "Epoch 71/200\n",
      " - 1s - loss: 0.5258 - acc: 0.7500 - val_loss: 0.7086 - val_acc: 0.7083\n",
      "Epoch 72/200\n",
      " - 1s - loss: 0.5043 - acc: 0.7812 - val_loss: 0.9343 - val_acc: 0.5833\n",
      "Epoch 73/200\n",
      " - 1s - loss: 0.4961 - acc: 0.7812 - val_loss: 1.0641 - val_acc: 0.4583\n",
      "Epoch 74/200\n",
      " - 1s - loss: 0.5208 - acc: 0.7604 - val_loss: 0.8274 - val_acc: 0.5833\n",
      "Epoch 75/200\n",
      " - 1s - loss: 0.5383 - acc: 0.7292 - val_loss: 0.9060 - val_acc: 0.5417\n",
      "Epoch 76/200\n",
      " - 1s - loss: 0.5041 - acc: 0.7292 - val_loss: 0.8328 - val_acc: 0.6667\n",
      "Epoch 77/200\n",
      " - 1s - loss: 0.4952 - acc: 0.7604 - val_loss: 0.7911 - val_acc: 0.6667\n",
      "Epoch 78/200\n",
      " - 1s - loss: 0.5059 - acc: 0.7500 - val_loss: 0.7785 - val_acc: 0.6667\n",
      "Epoch 79/200\n",
      " - 1s - loss: 0.4980 - acc: 0.7500 - val_loss: 0.9096 - val_acc: 0.5417\n",
      "Epoch 80/200\n",
      " - 1s - loss: 0.5334 - acc: 0.7188 - val_loss: 0.8110 - val_acc: 0.6667\n",
      "Epoch 81/200\n",
      " - 1s - loss: 0.4885 - acc: 0.7500 - val_loss: 0.7421 - val_acc: 0.7917\n",
      "Epoch 82/200\n",
      " - 1s - loss: 0.4925 - acc: 0.7396 - val_loss: 0.8596 - val_acc: 0.5833\n",
      "Epoch 83/200\n",
      " - 1s - loss: 0.4931 - acc: 0.7708 - val_loss: 0.9934 - val_acc: 0.5000\n",
      "Epoch 84/200\n",
      " - 1s - loss: 0.5090 - acc: 0.7708 - val_loss: 0.9122 - val_acc: 0.5000\n",
      "Epoch 85/200\n",
      " - 1s - loss: 0.4955 - acc: 0.7708 - val_loss: 0.7846 - val_acc: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      " - 1s - loss: 0.4968 - acc: 0.7708 - val_loss: 0.7942 - val_acc: 0.6667\n",
      "Epoch 87/200\n",
      " - 1s - loss: 0.4987 - acc: 0.7500 - val_loss: 0.8326 - val_acc: 0.5833\n",
      "Epoch 88/200\n",
      " - 1s - loss: 0.5027 - acc: 0.7708 - val_loss: 0.8679 - val_acc: 0.5833\n",
      "Epoch 89/200\n",
      " - 1s - loss: 0.4922 - acc: 0.7604 - val_loss: 0.8419 - val_acc: 0.5833\n",
      "Epoch 90/200\n",
      " - 1s - loss: 0.4980 - acc: 0.7708 - val_loss: 0.7821 - val_acc: 0.6667\n",
      "Epoch 91/200\n",
      " - 1s - loss: 0.4955 - acc: 0.7708 - val_loss: 0.7865 - val_acc: 0.6667\n",
      "Epoch 92/200\n",
      " - 1s - loss: 0.4999 - acc: 0.7292 - val_loss: 0.9304 - val_acc: 0.6667\n",
      "Epoch 93/200\n",
      " - 1s - loss: 0.4874 - acc: 0.7708 - val_loss: 0.8640 - val_acc: 0.5833\n",
      "Epoch 94/200\n",
      " - 1s - loss: 0.5049 - acc: 0.7500 - val_loss: 0.8089 - val_acc: 0.6250\n",
      "Epoch 95/200\n",
      " - 1s - loss: 0.4911 - acc: 0.7604 - val_loss: 0.7838 - val_acc: 0.6667\n",
      "Epoch 96/200\n",
      " - 1s - loss: 0.4932 - acc: 0.7604 - val_loss: 0.8147 - val_acc: 0.6250\n",
      "Epoch 97/200\n",
      " - 1s - loss: 0.5063 - acc: 0.7396 - val_loss: 0.8817 - val_acc: 0.5833\n",
      "Epoch 98/200\n",
      " - 1s - loss: 0.4922 - acc: 0.7500 - val_loss: 0.8019 - val_acc: 0.6667\n",
      "Epoch 99/200\n",
      " - 1s - loss: 0.4741 - acc: 0.7708 - val_loss: 0.7738 - val_acc: 0.6667\n",
      "Epoch 100/200\n",
      " - 1s - loss: 0.4937 - acc: 0.7708 - val_loss: 0.8348 - val_acc: 0.5833\n",
      "Epoch 101/200\n",
      " - 1s - loss: 0.4954 - acc: 0.7500 - val_loss: 0.7764 - val_acc: 0.7083\n",
      "Epoch 102/200\n",
      " - 1s - loss: 0.4829 - acc: 0.7604 - val_loss: 0.7672 - val_acc: 0.6667\n",
      "Epoch 103/200\n",
      " - 1s - loss: 0.4744 - acc: 0.7812 - val_loss: 0.8528 - val_acc: 0.6250\n",
      "Epoch 104/200\n",
      " - 1s - loss: 0.5014 - acc: 0.7708 - val_loss: 0.6998 - val_acc: 0.6667\n",
      "Epoch 105/200\n",
      " - 1s - loss: 0.4805 - acc: 0.7500 - val_loss: 0.6230 - val_acc: 0.8333\n",
      "Epoch 106/200\n",
      " - 1s - loss: 0.4837 - acc: 0.7604 - val_loss: 0.8257 - val_acc: 0.6250\n",
      "Epoch 107/200\n",
      " - 1s - loss: 0.4918 - acc: 0.7812 - val_loss: 0.6168 - val_acc: 0.7500\n",
      "Epoch 108/200\n",
      " - 1s - loss: 0.5221 - acc: 0.7500 - val_loss: 0.6800 - val_acc: 0.7083\n",
      "Epoch 109/200\n",
      " - 1s - loss: 0.4946 - acc: 0.7604 - val_loss: 0.5532 - val_acc: 0.8333\n",
      "Epoch 110/200\n",
      " - 1s - loss: 0.4894 - acc: 0.7708 - val_loss: 0.7741 - val_acc: 0.6667\n",
      "Epoch 111/200\n",
      " - 1s - loss: 0.4836 - acc: 0.7917 - val_loss: 0.7178 - val_acc: 0.7083\n",
      "Epoch 112/200\n",
      " - 1s - loss: 0.4790 - acc: 0.7604 - val_loss: 0.7424 - val_acc: 0.7083\n",
      "Epoch 113/200\n",
      " - 1s - loss: 0.5000 - acc: 0.7604 - val_loss: 0.8438 - val_acc: 0.6250\n",
      "Epoch 114/200\n",
      " - 1s - loss: 0.4822 - acc: 0.7500 - val_loss: 1.0325 - val_acc: 0.6667\n",
      "Epoch 115/200\n",
      " - 1s - loss: 0.4936 - acc: 0.7917 - val_loss: 0.7734 - val_acc: 0.6667\n",
      "Epoch 116/200\n",
      " - 1s - loss: 0.4711 - acc: 0.7708 - val_loss: 0.7711 - val_acc: 0.6667\n",
      "Epoch 117/200\n",
      " - 1s - loss: 0.4691 - acc: 0.7708 - val_loss: 0.7582 - val_acc: 0.6667\n",
      "Epoch 118/200\n",
      " - 1s - loss: 0.4960 - acc: 0.7604 - val_loss: 0.8068 - val_acc: 0.6250\n",
      "Epoch 119/200\n",
      " - 1s - loss: 0.5021 - acc: 0.7292 - val_loss: 0.9404 - val_acc: 0.7083\n",
      "Epoch 120/200\n",
      " - 1s - loss: 0.4946 - acc: 0.7812 - val_loss: 0.9352 - val_acc: 0.6667\n",
      "Epoch 121/200\n",
      " - 1s - loss: 0.5218 - acc: 0.7396 - val_loss: 1.2427 - val_acc: 0.0833\n",
      "Epoch 122/200\n",
      " - 1s - loss: 0.5171 - acc: 0.6771 - val_loss: 1.1424 - val_acc: 0.0833\n",
      "Epoch 123/200\n",
      " - 1s - loss: 0.4973 - acc: 0.6458 - val_loss: 0.9994 - val_acc: 0.5000\n",
      "Epoch 124/200\n",
      " - 1s - loss: 0.4926 - acc: 0.7500 - val_loss: 0.9964 - val_acc: 0.5833\n",
      "Epoch 125/200\n",
      " - 1s - loss: 0.4791 - acc: 0.7500 - val_loss: 1.2183 - val_acc: 0.5000\n",
      "Epoch 126/200\n",
      " - 1s - loss: 0.4861 - acc: 0.7292 - val_loss: 0.7566 - val_acc: 0.7500\n",
      "Epoch 127/200\n",
      " - 1s - loss: 0.4757 - acc: 0.7604 - val_loss: 0.8864 - val_acc: 0.6250\n",
      "Epoch 128/200\n",
      " - 1s - loss: 0.4619 - acc: 0.7812 - val_loss: 0.8477 - val_acc: 0.6667\n",
      "Epoch 129/200\n",
      " - 1s - loss: 0.4552 - acc: 0.7812 - val_loss: 0.9124 - val_acc: 0.6250\n",
      "Epoch 130/200\n",
      " - 1s - loss: 0.4659 - acc: 0.7604 - val_loss: 0.7966 - val_acc: 0.6667\n",
      "Epoch 131/200\n",
      " - 1s - loss: 0.4681 - acc: 0.7396 - val_loss: 0.8120 - val_acc: 0.6667\n",
      "Epoch 132/200\n",
      " - 1s - loss: 0.4723 - acc: 0.7708 - val_loss: 0.9211 - val_acc: 0.6250\n",
      "Epoch 133/200\n",
      " - 1s - loss: 0.4624 - acc: 0.7917 - val_loss: 0.9885 - val_acc: 0.6250\n",
      "Epoch 134/200\n",
      " - 1s - loss: 0.4829 - acc: 0.7917 - val_loss: 0.9438 - val_acc: 0.5833\n",
      "Epoch 135/200\n",
      " - 1s - loss: 0.4666 - acc: 0.7604 - val_loss: 0.8406 - val_acc: 0.6250\n",
      "Epoch 136/200\n",
      " - 1s - loss: 0.4701 - acc: 0.7396 - val_loss: 0.8368 - val_acc: 0.6667\n",
      "Epoch 137/200\n",
      " - 1s - loss: 0.4646 - acc: 0.7708 - val_loss: 0.7266 - val_acc: 0.7917\n",
      "Epoch 138/200\n",
      " - 1s - loss: 0.4968 - acc: 0.7500 - val_loss: 0.7896 - val_acc: 0.7083\n",
      "Epoch 139/200\n",
      " - 1s - loss: 0.4922 - acc: 0.7500 - val_loss: 0.7855 - val_acc: 0.7083\n",
      "Epoch 140/200\n",
      " - 1s - loss: 0.4786 - acc: 0.7917 - val_loss: 0.8339 - val_acc: 0.6250\n",
      "Epoch 141/200\n",
      " - 1s - loss: 0.5001 - acc: 0.7396 - val_loss: 0.9156 - val_acc: 0.5833\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-918d5c6eddef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m                              \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                              \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                              verbose=2)\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#評估準確率\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[0mfeed_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m         \u001b[0marray_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_initialized'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in range(5,50):\n",
    "    model = Sequential()\n",
    "    #輸入層：7, 隱藏層：50，輸出層：2\n",
    "    model.add(Dense(units=10, \n",
    "                    input_dim=7,\n",
    "                    kernel_initializer='normal',\n",
    "                    activation='sigmoid'))\n",
    "    model.add(Dense(units=2,\n",
    "                    kernel_initializer='normal',\n",
    "                    activation='softmax'))\n",
    "    #定義訓練方式\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    train_history =model.fit(x=train_data,\n",
    "                             y=train_label_onehot,\n",
    "                             validation_split=0.2, \n",
    "                             epochs=200,\n",
    "                             batch_size=1,\n",
    "                             verbose=2)\n",
    "\n",
    "    #評估準確率\n",
    "    scores = model.evaluate(test_data, test_label_onehot)\n",
    "    print('\\n準確率=',scores[1])\n",
    "    acc.append(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(5,50),acc,'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
